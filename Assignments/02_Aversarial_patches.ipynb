{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOs3RxNN7sKHj7rur7dibdG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mille055/AIPI590-XAI/blob/main/Assignments/02_Aversarial_patches.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2OkAhQG2V8n"
      },
      "source": [
        "<a href='https://ai.meng.duke.edu'> = <img align=\"left\" style=\"padding-top:10px;\" src=https://storage.googleapis.com/aipi_datasets/Duke-AIPI-Logo.png>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AIPI 590 - XAI | Assignment 02\n",
        "\n",
        "#Description: Adversarial Patch\n",
        "This notebook enables one to create and evaluate adversarial patches as a white box adversarial technique.\n",
        "\n",
        "## Chad Miller\n",
        "\n",
        "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mille055/AIPI590-XAI/blob/main/Assignments/02_Aversarial_patches.ipynb)"
      ],
      "metadata": {
        "id": "BOiHozMSBh28"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acknowledgements: Class Repository, Notebook 'Tutorial 10: Adversarial attacks\" authored by Phillip Lippe"
      ],
      "metadata": {
        "id": "5QIlTW-WBrTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Remove Colab default sample_data\n",
        "!rm -r /content/sample_data\n",
        "\n",
        "# Clone GitHub files to colab workspace\n",
        "repo_name = \"AIPI590-XAI\"\n",
        "git_path = 'https://github.com/mille055/AIPI590-XAI.git'\n",
        "!git clone \"{git_path}\"\n",
        "\n",
        "# Install dependencies from requirements.txt file\n",
        "!pip install -r \"{os.path.join(repo_name,'requirements.txt')}\"\n",
        "\n",
        "\n",
        "notebook_dir = 'Assignments'\n",
        "path_to_notebook = os.path.join(repo_name,notebook_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD5YGTd3Kin0",
        "outputId": "8c070686-409d-4f86-e1ca-421f9c721338"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AIPI590-XAI'...\n",
            "remote: Enumerating objects: 56, done.\u001b[K\n",
            "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 56 (delta 27), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (56/56), 45.08 KiB | 11.27 MiB/s, done.\n",
            "Resolving deltas: 100% (27/27), done.\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r AIPI590-XAI/requirements.txt (line 1)) (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r AIPI590-XAI/requirements.txt (line 2)) (0.19.0+cu121)\n",
            "Collecting adversarial-robustness-toolbox (from -r AIPI590-XAI/requirements.txt (line 3))\n",
            "  Downloading adversarial_robustness_toolbox-1.18.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r AIPI590-XAI/requirements.txt (line 1)) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r AIPI590-XAI/requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r AIPI590-XAI/requirements.txt (line 1)) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r AIPI590-XAI/requirements.txt (line 1)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r AIPI590-XAI/requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r AIPI590-XAI/requirements.txt (line 1)) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->-r AIPI590-XAI/requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r AIPI590-XAI/requirements.txt (line 2)) (9.4.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox->-r AIPI590-XAI/requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox->-r AIPI590-XAI/requirements.txt (line 3)) (1.3.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox->-r AIPI590-XAI/requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox->-r AIPI590-XAI/requirements.txt (line 3)) (71.0.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox->-r AIPI590-XAI/requirements.txt (line 3)) (4.66.5)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->adversarial-robustness-toolbox->-r AIPI590-XAI/requirements.txt (line 3)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->adversarial-robustness-toolbox->-r AIPI590-XAI/requirements.txt (line 3)) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r AIPI590-XAI/requirements.txt (line 1)) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r AIPI590-XAI/requirements.txt (line 1)) (1.3.0)\n",
            "Downloading adversarial_robustness_toolbox-1.18.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: adversarial-robustness-toolbox\n",
            "Successfully installed adversarial-robustness-toolbox-1.18.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Standard libraries\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "import tabulate\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "## Imports for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import set_matplotlib_formats\n",
        "#set_matplotlib_formats('svg', 'pdf') # For export\n",
        "from matplotlib.colors import to_rgb\n",
        "import matplotlib\n",
        "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "## Progress bar\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "## PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "# Torchvision\n",
        "import torchvision\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms, datasets\n",
        "import torchvision.transforms.functional as TF\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageNet\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VQo-GztgCHWl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get secrets if necessary\n",
        "# from google.colab import userdata\n",
        "# userdata.get('secretName')"
      ],
      "metadata": {
        "id": "X1XK-FbQPkvf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print('device is ', device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4EI_LpILkQ5",
        "outputId": "e558907b-c3fc-43d7-e75f-e1997b010ef5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device is  cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3orOj2Jh_gw",
        "outputId": "e04542d4-52af-44f3-d906-8bc0235b7283"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mAIPI590-XAI\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the paths where the zip files will be downloaded and extracted\n",
        "DATA_PATH = 'AIPI590-XAI/Assignments/data'\n",
        "CHECKPOINT_PATH = 'AIPI590-XAI/Assignments/checkpoints'\n",
        "\n",
        "# Ensure the directories exist\n",
        "os.makedirs(DATA_PATH, exist_ok=True)\n",
        "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
        "\n",
        "# Base URL for the files\n",
        "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial10/\"\n",
        "\n",
        "# List of files to download (path, filename)\n",
        "pretrained_files = [\n",
        "    (DATA_PATH, \"TinyImageNet.zip\"),\n",
        "    (CHECKPOINT_PATH, \"patches.zip\")\n",
        "]\n",
        "\n",
        "# Download and extract each file\n",
        "for path, filename in pretrained_files:\n",
        "    # Create the full download URL and the local file path\n",
        "    file_url = base_url + filename\n",
        "    file_path = os.path.join(path, filename)\n",
        "\n",
        "    # Download the file if it doesn't already exist\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"Downloading {filename}...\")\n",
        "        urllib.request.urlretrieve(file_url, file_path)\n",
        "        print(f\"Downloaded {filename}.\")\n",
        "    else:\n",
        "        print(f\"{filename} already exists.\")\n",
        "\n",
        "    # Extract the zip file\n",
        "    print(f\"Extracting {filename}...\")\n",
        "    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(path)\n",
        "    print(f\"Extracted {filename}.\")\n",
        "\n",
        "print(\"All files downloaded and extracted.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ckxyVxKg0qb",
        "outputId": "87fad3e9-086c-4754-f740-b58e7c3d395f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading TinyImageNet.zip...\n",
            "Downloaded TinyImageNet.zip.\n",
            "Extracting TinyImageNet.zip...\n",
            "Extracted TinyImageNet.zip.\n",
            "Downloading patches.zip...\n",
            "Downloaded patches.zip.\n",
            "Extracting patches.zip...\n",
            "Extracted patches.zip.\n",
            "All files downloaded and extracted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define the path to the TinyImageNet dataset\n",
        "data_dir = 'AIPI590-XAI/Assignments/data/TinyImageNet'\n",
        "\n",
        "# Define transformations\n",
        "preprocess = transforms.Compose([\n",
        "    #transforms.Resize(256), # already preprocessed\n",
        "    #transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load the dataset using ImageFolder\n",
        "tiny_imagenet_dataset = datasets.ImageFolder(root=data_dir, transform=preprocess)\n",
        "\n",
        "# DataLoader for batching the images\n",
        "data_loader = DataLoader(tiny_imagenet_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = len(tiny_imagenet_dataset.classes)\n",
        "print(f'Number of classes: {num_classes}')\n",
        "\n",
        "# Example: Access one batch of images and labels\n",
        "images, labels = next(iter(data_loader))\n",
        "print(f'Batch of images shape: {images.shape}')\n",
        "print(f'Batch of labels: {labels}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGZIUIWKjVA0",
        "outputId": "2be159ac-a6c1-4ac6-a6ce-5c2231f0ff68"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 1000\n",
            "Batch of images shape: torch.Size([32, 3, 224, 224])\n",
            "Batch of labels: tensor([980,   3, 932, 827, 209, 119, 613, 465, 368, 147, 815, 591, 405,  89,\n",
            "        665, 796, 267, 264, 856, 689, 172, 843, 232,  54, 757, 669, 477, 211,\n",
            "        998, 354, 885, 452])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the model\n",
        "pretrained_model = torchvision.models.resnet34(weights='IMAGENET1K_V1')\n",
        "pretrained_model = pretrained_model.to(device)\n",
        "\n",
        "# No gradients needed for the network\n",
        "pretrained_model.eval()\n",
        "for p in pretrained_model.parameters():\n",
        "    p.requires_grad = False"
      ],
      "metadata": {
        "id": "VmLlJWPcHN4Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f69dfdb-7867-4f54-8801-335602da135b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:01<00:00, 69.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Some constant values\n",
        "\n",
        "# ImageNet mean and std\n",
        "#NORM_MEAN = [0.4914, 0.4822, 0.4465]\n",
        "#NORM_STD = [0.2023, 0.1994, 0.2010]\n",
        "#TENSOR_MEANS, TENSOR_STD = torch.FloatTensor(NORM_MEAN)[:,None,None], torch.FloatTensor(NORM_STD)[:,None,None]\n",
        "\n",
        "# Transforms\n",
        "##plain_transforms = transforms.Compose([\n",
        "#    transforms.ToTensor(),\n",
        "#    transforms.Normalize(mean=NORM_MEAN,\n",
        "#                         std=NORM_STD)\n",
        "#])\n",
        "\n",
        "# Patch information\n",
        "class_names = ['basketball']\n",
        "patch_sizes = [32, 48, 64]\n",
        "\n",
        "with open(os.path.join('/content/', path_to_notebook, 'imagenet_classes.txt'), 'r') as f:\n",
        "  label_names = [line.strip() for line in f.readlines()]\n",
        "  target_class = label_names.index('basketball')\n"
      ],
      "metadata": {
        "id": "2azz9OunLX1g"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# places patch in random location without rotation\n",
        "def place_patch(img, patch):\n",
        "    for i in range(img.shape[0]):\n",
        "        h_offset = np.random.randint(0,img.shape[2]-patch.shape[1]-1)\n",
        "        w_offset = np.random.randint(0,img.shape[3]-patch.shape[2]-1)\n",
        "        img[i,:,h_offset:h_offset+patch.shape[1],w_offset:w_offset+patch.shape[2]] = patch_forward(patch)\n",
        "    return img"
      ],
      "metadata": {
        "id": "e_OlHzWsCZZK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# places patch in random location with rotation\n",
        "def place_patch(img, patch):\n",
        "    for i in range(img.shape[0]):\n",
        "        # Rotate random amount between 0 and 360 degrees\n",
        "        angle = np.random.uniform(0, 360)\n",
        "        rotated_patch = TF.rotate(patch, angle)\n",
        "\n",
        "        # Ensure the rotated patch still fits within the image\n",
        "        h_offset = np.random.randint(0, img.shape[2] - rotated_patch.shape[1] - 1)\n",
        "        w_offset = np.random.randint(0, img.shape[3] - rotated_patch.shape[2] - 1)\n",
        "\n",
        "        # Apply the patch to the image at the random location\n",
        "        img[i, :, h_offset:h_offset+rotated_patch.shape[1], w_offset:w_offset+rotated_patch.shape[2]] = patch_forward(rotated_patch)\n",
        "\n",
        "    return img"
      ],
      "metadata": {
        "id": "AXUhD6T2LcZ8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def patch_forward(patch):\n",
        "    # Map patch values from [-infty,infty] to ImageNet min and max\n",
        "    patch = (torch.tanh(patch) + 1 - 2 * TENSOR_MEANS) / (2 * TENSOR_STD)\n",
        "    return patch"
      ],
      "metadata": {
        "id": "4mDNvsvwCyZG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_patch(model, patch, val_loader, target_class):\n",
        "    model.eval()\n",
        "    tp, tp_5, counter = 0., 0., 0.\n",
        "    with torch.no_grad():\n",
        "        for img, img_labels in tqdm(val_loader, desc=\"Validating...\", leave=False):\n",
        "            # For stability, place the patch at 4 random locations per image, and average the performance\n",
        "            for _ in range(4):\n",
        "                patch_img = place_patch(img, patch)\n",
        "                patch_img = patch_img.to(device)\n",
        "                img_labels = img_labels.to(device)\n",
        "                pred = model(patch_img)\n",
        "                # In the accuracy calculation, we need to exclude the images that are of our target class\n",
        "                # as we would not \"fool\" the model into predicting those\n",
        "                tp += torch.logical_and(pred.argmax(dim=-1) == target_class, img_labels != target_class).sum()\n",
        "                tp_5 += torch.logical_and((pred.topk(5, dim=-1)[1] == target_class).any(dim=-1), img_labels != target_class).sum()\n",
        "                counter += (img_labels != target_class).sum()\n",
        "    acc = tp/counter\n",
        "    top5 = tp_5/counter\n",
        "    return acc, top5"
      ],
      "metadata": {
        "id": "VBalivOkC1oF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def patch_attack(model, target_class, patch_size=64, num_epochs=5):\n",
        "    # Leave a small set of images out to check generalization\n",
        "    #!mkdir -p data # create a directory to store the data if it doesn't exist\n",
        "    dataset = ImageNet(root='AIPI590-XAI/Assingments/data', train=True, download=True, transform=transforms.ToTensor())\n",
        "    train_set, val_set = torch.utils.data.random_split(dataset, [4500, 500])\n",
        "    train_loader = data.DataLoader(train_set, batch_size=32, shuffle=True, drop_last=True, num_workers=8)\n",
        "    val_loader = data.DataLoader(val_set, batch_size=32, shuffle=False, drop_last=False, num_workers=4)\n",
        "\n",
        "    # Create parameter and optimizer\n",
        "    if not isinstance(patch_size, tuple):\n",
        "        patch_size = (patch_size, patch_size)\n",
        "    patch = nn.Parameter(torch.zeros(3, patch_size[0], patch_size[1]), requires_grad=True)\n",
        "    optimizer = torch.optim.SGD([patch], lr=1e-1, momentum=0.8)\n",
        "    loss_module = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        t = tqdm(train_loader, leave=False)\n",
        "        for img, _ in t:\n",
        "            img = place_patch(img, patch)\n",
        "            img = img.to(device)\n",
        "            pred = model(img)\n",
        "            labels = torch.zeros(img.shape[0], device=pred.device, dtype=torch.long).fill_(target_class)\n",
        "            loss = loss_module(pred, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.mean().backward()\n",
        "            optimizer.step()\n",
        "            t.set_description(f\"Epoch {epoch}, Loss: {loss.item():4.2f}\")\n",
        "\n",
        "    # Final validation\n",
        "    acc, top5 = eval_patch(model, patch, val_loader, target_class)\n",
        "\n",
        "    return patch.data, {\"acc\": acc.item(), \"top5\": top5.item()}"
      ],
      "metadata": {
        "id": "Th3GTzIsC6Er"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load evaluation results of the pretrained patches\n",
        "json_results_file = os.path.join(CHECKPOINT_PATH, \"patch_results.json\")\n",
        "json_results = {}\n",
        "if os.path.isfile(json_results_file):\n",
        "    with open(json_results_file, \"r\") as f:\n",
        "        json_results = json.load(f)\n",
        "\n",
        "# If you train new patches, you can save the results via calling this function\n",
        "def save_results(patch_dict):\n",
        "    result_dict = {cname: {psize: [t.item() if isinstance(t, torch.Tensor) else t\n",
        "                                   for t in patch_dict[cname][psize][\"results\"]]\n",
        "                           for psize in patch_dict[cname]}\n",
        "                   for cname in patch_dict}\n",
        "    with open(os.path.join(CHECKPOINT_PATH, \"patch_results.json\"), \"w\") as f:\n",
        "        json.dump(result_dict, f, indent=4)"
      ],
      "metadata": {
        "id": "aPQmDtfpDDwE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial10/\"\n",
        "# Files to download\n",
        "pretrained_files = [(DATA_PATH, \"TinyImageNet.zip\"), (CHECKPOINT_PATH, \"patches.zip\")]"
      ],
      "metadata": {
        "id": "hLICJwxRTpce"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_patches(class_names, patch_sizes):\n",
        "    result_dict = dict()\n",
        "\n",
        "    # Loop over all classes and patch sizes\n",
        "    for name in class_names:\n",
        "        result_dict[name] = dict()\n",
        "        for patch_size in patch_sizes:\n",
        "            c = label_names.index(name)\n",
        "            file_name = os.path.join(CHECKPOINT_PATH, f\"{name}_{patch_size}_patch.pt\")\n",
        "            # Load patch if pretrained file exists, otherwise start training\n",
        "            if not os.path.isfile(file_name):\n",
        "                patch, val_results = patch_attack(pretrained_model, target_class=c, patch_size=patch_size, num_epochs=5)\n",
        "                print(f\"Validation results for {name} and {patch_size}:\", val_results)\n",
        "                torch.save(patch, file_name)\n",
        "            else:\n",
        "                patch = torch.load(file_name)\n",
        "            # Load evaluation results if exist, otherwise manually evaluate the patch\n",
        "            if name in json_results:\n",
        "                results = json_results[name][str(patch_size)]\n",
        "            else:\n",
        "                results = eval_patch(pretrained_model, patch, data_loader, target_class=c)\n",
        "\n",
        "            # Store results and the patches in a dict for better access\n",
        "            result_dict[name][patch_size] = {\n",
        "                \"results\": results,\n",
        "                \"patch\": patch\n",
        "            }\n",
        "\n",
        "    return result_dict"
      ],
      "metadata": {
        "id": "NpC_ncWfDIFw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patch_dict = get_patches(class_names, patch_sizes)\n",
        "# save_results(patch_dict) # Uncomment if you add new class names and want to save the new results"
      ],
      "metadata": {
        "id": "wyN73IqXDMxo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "d3ec2933-7a5c-4bbd-a32f-8d8905e1bae2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The archive ILSVRC2012_devkit_t12.tar.gz is not present in the root directory or is corrupted. You need to download it externally and place it in AIPI590-XAI/Assingments/data.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-3f613b4e182d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpatch_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_patches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# save_results(patch_dict) # Uncomment if you add new class names and want to save the new results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-ec2bc4062290>\u001b[0m in \u001b[0;36mget_patches\u001b[0;34m(class_names, patch_sizes)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# Load patch if pretrained file exists, otherwise start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0mpatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatch_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Validation results for {name} and {patch_size}:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-7079d3c77ec4>\u001b[0m in \u001b[0;36mpatch_attack\u001b[0;34m(model, target_class, patch_size, num_epochs)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Leave a small set of images out to check generalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#!mkdir -p data # create a directory to store the data if it doesn't exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'AIPI590-XAI/Assingments/data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, split, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverify_str_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_archives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mwnid_to_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_meta_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36mparse_archives\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_archives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMETA_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mparse_devkit_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36mparse_devkit_archive\u001b[0;34m(root, file)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mmd5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marchive_meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0m_verify_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_tmp_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtmp_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36m_verify_archive\u001b[0;34m(root, file, md5)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;34m\"You need to download it externally and place it in {}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         )\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The archive ILSVRC2012_devkit_t12.tar.gz is not present in the root directory or is corrupted. You need to download it externally and place it in AIPI590-XAI/Assingments/data."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_patches():\n",
        "    fig, ax = plt.subplots(len(patch_sizes), len(class_names), figsize=(len(class_names)*2.2, len(patch_sizes)*2.2))\n",
        "    for c_idx, cname in enumerate(class_names):\n",
        "        for p_idx, psize in enumerate(patch_sizes):\n",
        "            patch = patch_dict[cname][psize][\"patch\"]\n",
        "            patch = (torch.tanh(patch) + 1) / 2 # Parameter to pixel values\n",
        "            patch = patch.cpu().permute(1, 2, 0).numpy()\n",
        "            patch = np.clip(patch, a_min=0.0, a_max=1.0)\n",
        "            ax[p_idx][c_idx].imshow(patch)\n",
        "            ax[p_idx][c_idx].set_title(f\"{cname}, size {psize}\")\n",
        "            ax[p_idx][c_idx].axis('off')\n",
        "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
        "    plt.show()\n",
        "show_patches()"
      ],
      "metadata": {
        "id": "woTQME5tDSzm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "outputId": "ef3efbd4-9083-494c-e619-46f1ad1f5ec3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'patch_dict' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-299890e1d8fd>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots_adjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mshow_patches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-299890e1d8fd>\u001b[0m in \u001b[0;36mshow_patches\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsize\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mpatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpsize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"patch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mpatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;31m# Parameter to pixel values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mpatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'patch_dict' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 220x660 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%html\n",
        "<!-- Some HTML code to increase font size in the following table -->\n",
        "<style>\n",
        "th {font-size: 120%;}\n",
        "td {font-size: 120%;}\n",
        "</style>"
      ],
      "metadata": {
        "id": "alfX4-PiDWii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def show_table(top_1=True):\n",
        "    i = 0 if top_1 else 1\n",
        "    table = [[name] + [f\"{(100.0 * patch_dict[name][psize]['results'][i]):4.2f}%\" for psize in patch_sizes]\n",
        "             for name in class_names]\n",
        "    display(HTML(tabulate.tabulate(table, tablefmt='html', headers=[\"Class name\"] + [f\"Patch size {psize}x{psize}\" for psize in patch_sizes])))"
      ],
      "metadata": {
        "id": "8SPe7RQhDZmB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}